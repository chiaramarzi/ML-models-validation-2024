{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1gvGP7WcCe1JJBZ5_HqgmvR_73QGLis3E",
      "authorship_tag": "ABX9TyMKSxDS3/KajJd0dFZE39xA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiaramarzi/ML-models-validation-2024/blob/main/model_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Artificial intelligence (AI) for health - potentials"
      ],
      "metadata": {
        "id": "VnJ86NLFWZu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Data mining**: finding pattern in big data\n",
        "*   **Biomarker discovery**: determining potential (compound) biomarkers\n",
        "*   The **predicitive nature** of machine learning strategies is highly in line with the aim of clinical diagnosis and prognosis **in the single patient**"
      ],
      "metadata": {
        "id": "PdmYJBhKWdPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models validation"
      ],
      "metadata": {
        "id": "6abprWZRWi_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In machine learning, model validation is referred to as the process where a trained model is evaluated with a testing data set. The testing data set is a separate portion of the same data set from which the training set is derived.\n",
        "Model validation is carried out after model training.\n",
        "\n",
        "Estimation of **unbiased generalization performance** of the model"
      ],
      "metadata": {
        "id": "PAFJwHRaWmt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gene mutation prediction based on neuroimaging features"
      ],
      "metadata": {
        "id": "zUcef_MloSgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Can we predict the presence/absence of genetic mutation using neuorimaging features?\n",
        "*   Data: multicenter dataset containing the radiomics features extracted from brain lesions segmented on T1- and T2-weighted MR images\n",
        "  * 250 patients, examined in 10 institutions (different MRI scanners and protocols), 25 patients for each institution\n",
        "  * Each patient presents a brain lesion, visible in 3D T1- and T2-weighted MR images\n",
        "  * 200 radiomic features (100 from T1-weighted MR image and 100 from T2-weighted MR image) describing the lesion's morphology, contrast, texture, etc.\n",
        "  * Each patient underwent genetic testing to determine if they had a specific genetic mutation\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "V6_OxaEZoc02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outline"
      ],
      "metadata": {
        "id": "Kf0OaSY2WsZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple validation schemes:\n",
        "1.   Holdout validation\n",
        "2.   K-fold cross-validation (kfoldCV)\n",
        "3.   Leave-One-Out CV (LOOCV)\n",
        "4.   Group K-Fold Cross-Validation (gkfoldCV)\n",
        "5.   Leave-One-Group-Out CV (LOGOCV)\n",
        "\n",
        "Sampling bias:\n",
        "6.   Repetition of holdout validation\n",
        "\n",
        "Unbalanced datasets\n",
        "7.   Stratified holdout validation\n",
        "8.   Stratified kfoldCV\n",
        "\n",
        "Hyperparameters tuning:\n",
        "9.   Training, validation and test set: the nested kfoldCV\n",
        "\n"
      ],
      "metadata": {
        "id": "8XfngQ-PWv0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cloning repository, libraries and data loading"
      ],
      "metadata": {
        "id": "I-gXlmixpVEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries loading\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import (train_test_split, KFold, StratifiedKFold,\n",
        "                                     LeaveOneOut, LeaveOneGroupOut, ShuffleSplit,\n",
        "                                     GroupKFold, cross_validate, GridSearchCV)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "HHOLfos-arhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"drive/MyDrive/Colab Notebooks/\""
      ],
      "metadata": {
        "id": "3aKKAMWUO4id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading\n",
        "data = pd.read_csv(\"simulated_data.csv\")\n",
        "X = data.iloc[:, 2::]\n",
        "y = data[\"Gene_mutation\"]\n",
        "groups = data[\"Institution\"]"
      ],
      "metadata": {
        "id": "2CUCSE_ha57I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groups"
      ],
      "metadata": {
        "id": "iUwmt94oPPRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest classifier inizialization\n",
        "model = RandomForestClassifier(random_state = 42)"
      ],
      "metadata": {
        "id": "oImV8G5zbBb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Holdout validation"
      ],
      "metadata": {
        "id": "Jqmm7A7rpFh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The principle is simple, you simply split your data randomly into roughly X% used for training the model and (1-X)% for testing the model.\n",
        "\n",
        "FIGURA\n"
      ],
      "metadata": {
        "id": "LEoglmOYpcMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Train-Test Split\n",
        "print(\"1. Train-Test Split\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = None)\n",
        "print(\"Training set:\", list(X_train.index))\n",
        "print(\"Test set:\", list(X_test.index))\n",
        "model.fit(X_train, y_train)\n",
        "train_acc = accuracy_score(y_train, model.predict(X_train))\n",
        "test_acc = accuracy_score(y_test, model.predict(X_test))\n",
        "print('#####')\n",
        "print(f\"Training Accuracy: {train_acc}\")\n",
        "print(f\"Test Accuracy: {test_acc}\\n\")"
      ],
      "metadata": {
        "id": "_8OwDdthbIqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. K-fold cross-validation (kfoldCV)"
      ],
      "metadata": {
        "id": "JHpZSTi4plZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It splits the data into k folds, then trains the data on k-1 folds and test on the one fold that was left out. It does this for all folds and averages the results obtained in the k test folds.  \n",
        "\n",
        "FIGURA\n",
        "\n",
        "The advantage is that all observations are used for both training and validation, and each observation is used once for validation.\n",
        "\n",
        "We typically choose either k=5 or k=10 as they find a nice balance between computational complexity and validation accuracy.\n",
        "\n",
        "The scores of each fold from CV techniques are more insightful than one may think. They are mostly used to simply extract the average performance. However, one might also look at the variance or standard deviation of the resulting folds as it will give information about the stability of the model across different data inputs."
      ],
      "metadata": {
        "id": "3nsnYJ4VpkJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. K-Fold Cross-Validation\n",
        "print(\"2. K-Fold Cross-Validation\")\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    print(f\"Fold {i}:\")\n",
        "    print(f\"  Train: index={train_index}\")\n",
        "    print(f\"  Test:  index={test_index}\")\n",
        "\n",
        "scores = cross_validate(model, X, y, cv = kf, scoring='accuracy', return_train_score=True)\n",
        "print('#####')\n",
        "print(f\"Training Accuracies: {scores['train_score']}\")\n",
        "print(f\"Test Accuracies: {scores['test_score']}\\n\")\n",
        "print(f\"Mean Training Accuracy: {np.mean(scores['train_score'])}\")\n",
        "print(f\"Std Training Accuracy: {np.std(scores['train_score'])}\\n\")\n",
        "print(f\"Mean Test Accuracy: {np.mean(scores['test_score'])}\")\n",
        "print(f\"Std Test Accuracy: {np.std(scores['test_score'])}\\n\")"
      ],
      "metadata": {
        "id": "ypqxYs1ybvMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Leave-One-Out CV (LOOCV)"
      ],
      "metadata": {
        "id": "Evktd9ZhqoHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A variant of k-fold CV is Leave-one-out Cross-Validation (LOOCV).\n",
        "\n",
        "LOOCV uses each sample in the data as a separate test set while all remaining samples form the training set. This variant is identical to k-fold CV when k = n (number of observations).\n",
        "\n",
        "LOOCV is computationally very costly as the model needs to be trained n times. Only do this if the dataset is small or if you can handle that many computations."
      ],
      "metadata": {
        "id": "ZaSeWG2ZqoPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Leave-One-Out Cross-Validation (LOO)\n",
        "print(\"3. Leave-One-Out Cross-Validation (LOO)\")\n",
        "loo = LeaveOneOut()\n",
        "scores = cross_validate(model, X, y, cv = loo, scoring='accuracy', return_train_score=True)\n",
        "print('#####')\n",
        "print(f\"Training Accuracies: {scores['train_score']}\")\n",
        "print(f\"Test Accuracies: {scores['test_score']}\\n\")\n",
        "print(f\"Mean Training Accuracy: {np.mean(scores['train_score'])}\")\n",
        "print(f\"Std Training Accuracy: {np.std(scores['train_score'])}\\n\")\n",
        "print(f\"Mean Test Accuracy: {np.mean(scores['test_score'])}\")\n",
        "print(f\"Std Test Accuracy: {np.std(scores['test_score'])}\\n\")"
      ],
      "metadata": {
        "id": "3qhhnqOGr8zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Group K-Fold Cross-Validation (gkfoldCV)"
      ],
      "metadata": {
        "id": "-Q2eY7boq1X-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a variant of the conventional kfoldsCV, which encapsulates in the validation scheme a peculiar structure of the dataset, i.e., the presence of a hierarchical structure.  \n",
        "Each \"parent node\", called \"group\" in machine lerning terminology, will appear exactly once in the test set across all folds (the number of distinct groups has to be at least equal to the number of folds).\n",
        "\n",
        "FIGURA DA FARE"
      ],
      "metadata": {
        "id": "8xhMDYy-rIJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Group K-Fold Cross-Validation\n",
        "print(\"4. Group K-Fold Cross-Validation\")\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "for i, (train_index, test_index) in enumerate(gkf.split(X, y, groups)):\n",
        "    print(f\"Fold {i}:\")\n",
        "    print(f\"  Train: index={train_index}, group={list(groups[train_index])}\")\n",
        "    print(f\"  Test:  index={test_index}, group={list(groups[test_index])}\")\n",
        "scores = cross_validate(model, X, y, groups = groups, cv = gkf, scoring='accuracy', return_train_score=True)\n",
        "print('#####')\n",
        "print(f\"Training Accuracies: {scores['train_score']}\")\n",
        "print(f\"Test Accuracies: {scores['test_score']}\\n\")\n",
        "print(f\"Mean Training Accuracy: {np.mean(scores['train_score'])}\")\n",
        "print(f\"Std Training Accuracy: {np.std(scores['train_score'])}\\n\")\n",
        "print(f\"Mean Test Accuracy: {np.mean(scores['test_score'])}\")\n",
        "print(f\"Std Test Accuracy: {np.std(scores['test_score'])}\\n\")"
      ],
      "metadata": {
        "id": "xIwfsepNvSfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Leave-One-Group-Out CV (LOGOCV)"
      ],
      "metadata": {
        "id": "ncw-W1kesVIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a variant of the conventional LOOCV, which encapsulates in the validation scheme a peculiar structure of the dataset, i.e., the presence of a hierarchical structure.  \n",
        "Each \"parent node\", called \"group\" in machine lerning terminology, will appear exactly once in the test set."
      ],
      "metadata": {
        "id": "jQHxSU8HsYP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Leave-One-Group-Out Cross-Validation\n",
        "print(\"5. Leave-One-Group-Out Cross-Validation\")\n",
        "logo = LeaveOneGroupOut()\n",
        "for i, (train_index, test_index) in enumerate(logo.split(X, y, groups)):\n",
        "    print(f\"Fold {i}:\")\n",
        "    print(f\"  Train: index={train_index}, group={list(groups[train_index])}\")\n",
        "    print(f\"  Test:  index={test_index}, group={list(groups[test_index])}\")\n",
        "scores = cross_validate(model, X, y, groups = groups, cv = logo, scoring='accuracy', return_train_score=True)\n",
        "print('#####')\n",
        "print(f\"Training Accuracies: {scores['train_score']}\")\n",
        "print(f\"Test Accuracies: {scores['test_score']}\\n\")\n",
        "print(f\"Mean Training Accuracy: {np.mean(scores['train_score'])}\")\n",
        "print(f\"Std Training Accuracy: {np.std(scores['train_score'])}\\n\")\n",
        "print(f\"Mean Test Accuracy: {np.mean(scores['test_score'])}\")\n",
        "print(f\"Std Test Accuracy: {np.std(scores['test_score'])}\\n\")"
      ],
      "metadata": {
        "id": "C4WCz3r_x6nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling bias"
      ],
      "metadata": {
        "id": "-zxlF19Yx2N_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if one subset of our data only have people of a certain age or income levels? This is typically referred to as a sampling bias.\n",
        "\n",
        "**Sampling bias** is systematic error due to a non-random sample of a population, causing some members of the population to be less likely to be included than others, resulting in a biased sample.\n",
        "\n",
        "Choosing and using a validation scheme leads to potentially sampling bias in practice. One possible solution is the n-times repetition of the validation scheme."
      ],
      "metadata": {
        "id": "0LrfLCE0x22k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Repetition of holdout validation"
      ],
      "metadata": {
        "id": "37r2kK5cy8G9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One way to overcome the sampling bias is the **n-times repetition** of the validation method, changing the seed of the pseudo-random numbers generator, that determines the data splitting.\n",
        "\n",
        "The performances on the different test sets will be averaged."
      ],
      "metadata": {
        "id": "cumVFxOyzCbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. ShuffleSplit\n",
        "print(\"6. ShuffleSplit\")\n",
        "ss = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
        "for i, (train_index, test_index) in enumerate(ss.split(X)):\n",
        "    print(f\"Fold {i}:\")\n",
        "    print(f\"  Train: index={train_index}\")\n",
        "    print(f\"  Test:  index={test_index}\")\n",
        "    if 0 in list(test_index):\n",
        "      print()\n",
        "      print(\"0 found in the test set.\")\n",
        "      print()\n",
        "scores = cross_validate(model, X, y, cv = ss, scoring='accuracy', return_train_score=True)\n",
        "print('#####')\n",
        "print(f\"Training Accuracies: {scores['train_score']}\")\n",
        "print(f\"Test Accuracies: {scores['test_score']}\\n\")\n",
        "print(f\"Mean Training Accuracy: {np.mean(scores['train_score'])}\")\n",
        "print(f\"Std Training Accuracy: {np.std(scores['train_score'])}\\n\")\n",
        "print(f\"Mean Test Accuracy: {np.mean(scores['test_score'])}\")\n",
        "print(f\"Std Test Accuracy: {np.std(scores['test_score'])}\\n\")"
      ],
      "metadata": {
        "id": "n2CS7q9Y1PxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unbalanced datasets"
      ],
      "metadata": {
        "id": "gEHIi2t6zNJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some cases, there may be a large imbalance in the response variables.\n",
        "\n",
        "For example, in case of classification, there might be several times more negative samples than positive samples. For such problems, a slight variation in the simple cross validation technique is made, such that each fold contains approximately the same percentage of samples of each target class as the complete dataset."
      ],
      "metadata": {
        "id": "lXFs4DZVzTzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Stratified holdout validation"
      ],
      "metadata": {
        "id": "GCqOQrCjzgAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Stratified Train-Test Split\n",
        "print(\"1. Stratified Train-Test Split\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)\n",
        "model.fit(X_train, y_train)\n",
        "train_acc = accuracy_score(y_train, model.predict(X_train))\n",
        "test_acc = accuracy_score(y_test, model.predict(X_test))\n",
        "print('#####')\n",
        "print(f\"Training Accuracy: {train_acc}\")\n",
        "print(f\"Test Accuracy: {test_acc}\\n\")"
      ],
      "metadata": {
        "id": "kXDpj2eB1tKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Stratified kfoldCV"
      ],
      "metadata": {
        "id": "ILCUpoZCzrcX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmOg5GbWafzw"
      },
      "outputs": [],
      "source": [
        "# 8. Stratified K-Fold Cross-Validation\n",
        "print(\"8. Stratified K-Fold Cross-Validation\")\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_validate(model, X, y, cv = skf, scoring='accuracy', return_train_score=True)\n",
        "print('#####')\n",
        "print(f\"Training Accuracies: {scores['train_score']}\")\n",
        "print(f\"Test Accuracies: {scores['test_score']}\\n\")\n",
        "print(f\"Mean Training Accuracy: {np.mean(scores['train_score'])}\")\n",
        "print(f\"Std Training Accuracy: {np.std(scores['train_score'])}\\n\")\n",
        "print(f\"Mean Test Accuracy: {np.mean(scores['test_score'])}\")\n",
        "print(f\"Std Test Accuracy: {np.std(scores['test_score'])}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters tuning"
      ],
      "metadata": {
        "id": "ZIIAIoUDz39e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A random forest classifier is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. For classification tasks, the output of the random forest is the class selected by most trees (the modal response).\n",
        "\n",
        "While random forests often achieve higher accuracy than a single decision tree, they sacrifice the intrinsic interpretability present in decision trees. Decision trees are among a fairly small family of machine learning models that are easily interpretable along with linear models, rule-based models, and attention-based models. This interpretability is one of the most desirable qualities of decision trees. It allows developers to confirm that the model has learned realistic information from the data and allows end-users to have trust and confidence in the decisions made by the model[1]. For example, following the path that a decision tree takes to make its decision is quite trivial, but following the paths of tens or hundreds of trees is much harder. To achieve both performance and interpretability, some model compression techniques allow transforming a random forest into a minimal \"born-again\" decision tree that faithfully reproduces the same decision function [2, 3].\n",
        "\n",
        "Random forest classifier has, among others, the following **hyperparameters**:\n",
        "- *n_estimators*, default=100: the number of trees in the forest\n",
        "- *max_depth*, default=None: the maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than *min_samples_split* samples\n",
        "- *min_samples_split*, default=2: the minimum number of samples required to split an internal node\n",
        "- *min_samples_leaf*, default=1: the minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least *min_samples_leaf* training samples in each of the left and right branches\n",
        "- *max_features*, default=”sqrt” (alternatives: \"log2\", None, int): the number of features to consider when looking for the best split\n",
        "\n",
        "**References**   \n",
        "[1] Hastie, Trevor; Tibshirani, Robert; Friedman, Jerome (2008). The Elements of Statistical Learning (2nd ed.). Springer. ISBN 0-387-95284-5.   \n",
        "[2] Sagi, Omer; Rokach, Lior (2020). \"Explainable decision forest: Transforming a decision forest into an interpretable tree\". Information Fusion. 61: 124–138. doi:10.1016/j.inffus.2020.03.013. S2CID 216444882.   \n",
        "[3] Vidal, Thibaut; Schiffer, Maximilian (2020). \"Born-Again Tree Ensembles\". International Conference on Machine Learning. 119. PMLR: 9743–9753. arXiv:2003.11132."
      ],
      "metadata": {
        "id": "QRaLCgeqz96H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you are optimizing the hyperparameters of your model and you use the same k-Fold CV strategy to tune the model and evaluate performance, you run the risk of overfitting. You do not want to estimate the accuracy of your model on the same split that you found the best hyperparameters for.\n",
        "\n",
        "\n",
        "Instead, we use a Nested kfold Cross-Validation strategy allowing to separate the hyperparameter tuning step from the error estimation step. To do this, we nest two k-fold cross-validation loops:\n",
        "\n",
        "\n",
        "*   The inner loop for hyperparameter tuning and\n",
        "*   the outer loop for estimating accuracy\n",
        "\n",
        "FIGURA"
      ],
      "metadata": {
        "id": "HlZVfft77sCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Nested kfoldCV"
      ],
      "metadata": {
        "id": "W12Yfn0l76hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Nested kfoldCV\n",
        "outer_cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
        "inner_cv = KFold(n_splits=2, shuffle=True, random_state=0)\n",
        "\n",
        "clf = RandomForestClassifier(random_state = 42)\n",
        "param_grid = {\n",
        "\t'n_estimators': [10, 20, 25],\n",
        "\t'max_depth': [2, 3, 4],\n",
        "\t'max_features': [None, \"sqrt\", \"log2\"],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(clf,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=inner_cv,\n",
        "                           refit='accuracy',\n",
        "                           scoring='accuracy',\n",
        "                           n_jobs=1,\n",
        "                           verbose = 4)\n",
        "score = cross_validate(grid_search, X=X, y=y, cv=outer_cv, return_train_score=True, return_estimator=True, scoring = 'accuracy', n_jobs=1)\n",
        "\n",
        "print('#####')\n",
        "print(f\"Training Accuracies: {score['train_score']}\")\n",
        "print(f\"Test Accuracies: {score['test_score']}\\n\")\n",
        "print(f\"Mean Training Accuracy: {np.mean(score['train_score'])}\")\n",
        "print(f\"Std Training Accuracy: {np.std(score['train_score'])}\\n\")\n",
        "print(f\"Mean Test Accuracy: {np.mean(score['test_score'])}\")\n",
        "print(f\"Std Test Accuracy: {np.std(score['test_score'])}\\n\")\n",
        "print(score['estimator'][0].best_estimator_)\n",
        "print(score['estimator'][1].best_estimator_)\n",
        "print(score['estimator'][2].best_estimator_)"
      ],
      "metadata": {
        "id": "U3uIkh-OeX-h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}