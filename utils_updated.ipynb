{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "utils.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiaramarzi/ML-models-validation-2024/blob/main/utils_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAGkTpi_Z6Hk"
      },
      "source": [
        "def classification_holdout(X, y, seed, test_size, stratify):\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : TYPE\n",
        "        DESCRIPTION.\n",
        "    y : TYPE\n",
        "        DESCRIPTION.\n",
        "    seed : TYPE\n",
        "        DESCRIPTION.\n",
        "    test_size : TYPE\n",
        "        DESCRIPTION.\n",
        "    stratify : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None.\n",
        "\n",
        "    '''\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed, shuffle=True, stratify=stratify)\n",
        "\n",
        "    #clf = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
        "    clf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=0, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred_train = clf.predict(X_train)\n",
        "    y_pred_test = clf.predict_proba(X_test)[:, 1]\n",
        "    print(\"AUROC train\", roc_auc_score(y_train, y_pred_train))\n",
        "    print(\"AUROC test\", roc_auc_score(y_test, y_pred_test))\n",
        "    print()\n",
        "\n",
        "################################################################################\n",
        "\n",
        "def classification_CV(X, y, seed, n_folds):\n",
        "    '''\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : TYPE\n",
        "        DESCRIPTION.\n",
        "    y : TYPE\n",
        "        DESCRIPTION.\n",
        "    seed : TYPE\n",
        "        DESCRIPTION.\n",
        "    n_folds : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None.\n",
        "\n",
        "    '''\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    kf = KFold(n_splits= n_folds, random_state=seed, shuffle=True)\n",
        "    Iteration = 1\n",
        "    ACC_train = []\n",
        "    ACC_test = []\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        print(\"* Iteration:\", Iteration)\n",
        "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        #clf = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
        "        clf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=0, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred_train = clf.predict(X_train)\n",
        "        y_pred_test = clf.predict(X_test)\n",
        "        ACC_tr= accuracy_score(y_train, y_pred_train)\n",
        "        ACC_train.append(ACC_tr)\n",
        "        ACC_te= accuracy_score(y_test, y_pred_test)\n",
        "        ACC_test.append(ACC_te)\n",
        "        print(\"ACC train\", ACC_tr)\n",
        "        print(\"ACC test\", ACC_te)\n",
        "        print()\n",
        "        Iteration += 1\n",
        "    return ACC_train, ACC_test\n",
        "\n",
        "################################################################################\n",
        "\n",
        "def print_to_std(score_train, score_test, score_name):\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    score_train : TYPE\n",
        "        DESCRIPTION.\n",
        "    score_test : TYPE\n",
        "        DESCRIPTION.\n",
        "    score_name : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None.\n",
        "\n",
        "    '''\n",
        "    print(\"#########################################################\")\n",
        "    print(\"Average \" + score_name + \" train:\", np.mean(score_train))\n",
        "    print(\"Std \" + score_name + \" train:\", np.std(score_train))\n",
        "    print(\"Average \" + score_name + \" test:\", np.mean(score_test))\n",
        "    print(\"Std \" + score_name + \" test:\", np.std(score_test))\n",
        "    print(\"#########################################################\")\n",
        "    print()\n",
        "\n",
        "################################################################################\n",
        "\n",
        "def classification_holdout_val_set(X, y, seed, test_set_size, val_set_size, n_trees):\n",
        "    '''\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : TYPE\n",
        "        DESCRIPTION.\n",
        "    y : TYPE\n",
        "        DESCRIPTION.\n",
        "    seed : TYPE\n",
        "        DESCRIPTION.\n",
        "    test_set_size : TYPE\n",
        "        DESCRIPTION.\n",
        "    val_set_size : TYPE\n",
        "        DESCRIPTION.\n",
        "    n_trees : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None.\n",
        "\n",
        "    '''\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=test_set_size, random_state=seed, shuffle=True)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=val_set_size, random_state=seed, shuffle=True)\n",
        "    n_trees = n_trees\n",
        "    ACC_train = []\n",
        "    ACC_val = []\n",
        "    for n in n_trees:\n",
        "        print(\"Training with number of trees equal to:\", n)\n",
        "        #clf = SVC(C=c, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
        "        clf = RandomForestClassifier(n_estimators=n, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=0, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred_train = clf.predict(X_train)\n",
        "        y_pred_val = clf.predict(X_val)\n",
        "        ACC_tr= accuracy_score(y_train, y_pred_train)\n",
        "        ACC_train.append(ACC_tr)\n",
        "        ACC_v= accuracy_score(y_val, y_pred_val)\n",
        "        ACC_val.append(ACC_v)\n",
        "        print(\"ACC train:\", ACC_tr)\n",
        "        print(\"ACC val:\", ACC_v)\n",
        "        print()\n",
        "    #MAE_best = np.min(MAE_val)\n",
        "    ACC_best_ind = np.argmax(ACC_val)\n",
        "    n_best = n_trees[ACC_best_ind]\n",
        "    print(\"Best number of trees param on validation set:\", n_best)\n",
        "    #clf = SVC(C=C_best, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
        "    clf = RandomForestClassifier(n_estimators=n_best, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=0, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
        "    clf.fit(X_train_val, y_train_val)\n",
        "    y_pred_train_val = clf.predict(X_train_val)\n",
        "    y_pred_test = clf.predict(X_test)\n",
        "    ACC_tr_v= accuracy_score(y_train_val, y_pred_train_val)\n",
        "    ACC_te= accuracy_score(y_test, y_pred_test)\n",
        "    print(\"ACC train_val:\", ACC_tr_v)\n",
        "    print(\"ACC test:\", ACC_te)\n",
        "    print()\n",
        "\n",
        "################################################################################\n",
        "\n",
        "def classification_nestedCV(X, y, seed, outer_n_folds, inner_n_folds, n_trees):\n",
        "    '''\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : TYPE\n",
        "        DESCRIPTION.\n",
        "    y : TYPE\n",
        "        DESCRIPTION.\n",
        "    seed : TYPE\n",
        "        DESCRIPTION.\n",
        "    outer_n_folds : TYPE\n",
        "        DESCRIPTION.\n",
        "    inner_n_folds : TYPE\n",
        "        DESCRIPTION.\n",
        "    n_trees : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None.\n",
        "\n",
        "    '''\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    outer_kf = KFold(n_splits= outer_n_folds, random_state=seed, shuffle=True)\n",
        "    inner_kf = KFold(n_splits= inner_n_folds, random_state=seed, shuffle=True)\n",
        "    Outer_iteration = 1\n",
        "    ACC_tr_val = []\n",
        "    ACC_test = []\n",
        "    n_trees = n_trees #[1, 100]\n",
        "    for train_val_index, test_index in outer_kf.split(X):\n",
        "        print(\"*** Outer iteration:\", Outer_iteration)\n",
        "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "        X_train_val, X_test = X[train_val_index], X[test_index]\n",
        "        y_train_val, y_test = y[train_val_index], y[test_index]\n",
        "        ACC_tmp = []\n",
        "        for n in n_trees:\n",
        "            print(\"Training with number of trees equal to:\", n)\n",
        "            ACC_train = []\n",
        "            ACC_val = []\n",
        "            Inner_iteration = 1\n",
        "            for train_index, val_index in inner_kf.split(X_train_val):\n",
        "                #print(\"* Inner iteration:\", Inner_iteration)\n",
        "                #print(train_val_index)\n",
        "                #print(train_index)\n",
        "                X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
        "                y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
        "                #clf = SVC(C=c, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=0, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=seed)\n",
        "                clf = RandomForestClassifier(n_estimators=n, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=0, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
        "                clf.fit(X_train, y_train)\n",
        "                y_pred_train = clf.predict(X_train)\n",
        "                y_pred_val = clf.predict(X_val)\n",
        "                ACC_tr= accuracy_score(y_train, y_pred_train)\n",
        "                ACC_train.append(ACC_tr)\n",
        "                ACC_v= accuracy_score(y_val, y_pred_val)\n",
        "                ACC_val.append(ACC_v)\n",
        "                print(\"* Inner iteration: \" + str(Inner_iteration) + \" with ACC: \" + str(ACC_v))\n",
        "                Inner_iteration += 1\n",
        "            ACC_tmp.append(np.mean(ACC_val))\n",
        "        print(\"Average ACC on validation set\", ACC_tmp)\n",
        "        ACC_best_ind = np.argmax(ACC_tmp)\n",
        "        n_best = n_trees[ACC_best_ind]\n",
        "        print(\"Best number of trees param on validation set:\", n_best)\n",
        "        #clf = SVC(C=C_best, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=0, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=seed)\n",
        "        clf = RandomForestClassifier(n_estimators=n_best, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=0, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
        "        clf.fit(X_train_val, y_train_val)\n",
        "        y_pred_train_val = clf.predict(X_train_val)\n",
        "        y_pred_test = clf.predict(X_test)\n",
        "        ACC_tr_v= accuracy_score(y_train_val, y_pred_train_val)\n",
        "        ACC_tr_val.append(ACC_tr_v)\n",
        "        ACC_te= accuracy_score(y_test, y_pred_test)\n",
        "        ACC_test.append(ACC_te)\n",
        "        #print(\"MAE train_val:\", MAE_tr_v)\n",
        "        #print(\"MAE test:\", MAE_te)\n",
        "        #print()\n",
        "        Outer_iteration += 1\n",
        "\n",
        "    return ACC_tr_val, ACC_test"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}